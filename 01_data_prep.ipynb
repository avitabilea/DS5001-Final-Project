{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93487bc1-6d19-42ee-a512-25e1006ef907",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course:   DS5001: Exploratory Text Analytics\n",
    "Topic:    Final Project, Data Prep\n",
    "Author:   Andrew Avitabile\n",
    "Date:     24 March 2024 (Edited April 25, 2024)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05f642-d52d-4b07-94ee-f87a29b2a4ab",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0c0b9-d1c2-449f-83fd-c8961b34b441",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5dc02c-114c-47a8-9ba6-783214eec4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#nltk packages\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Downloading necessary data from nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "# Creating a list of stop words for later use\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize Porter Stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9173f3-c8ce-4c7d-a8b4-ae0f66b745ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the base path\n",
    "base_path = \"C:/Users/Andre/Box/DS5001 Final Project/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0fc8e-506e-44a8-a72b-bdb8ce9c2170",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afd4b495-d3f3-4925-8ead-7a9fa22916e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define filepaths\n",
    "file_path_eval_text = base_path + \"Data/eval_text.xlsx\"\n",
    "\n",
    "# Read the CSV file\n",
    "eval_text = pd.read_excel(file_path_eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b8e8e7-d265-4004-9496-269dafa56ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get just PST feedback. Replace missing feedback with blank strings.\n",
    "eval_text['overallcomments'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b58335-a282-4ed5-990c-3ee8687edd4d",
   "metadata": {},
   "source": [
    "# Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bc5b9-77d8-4f37-85da-f6a7df1e501a",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d72962-c9c3-4605-9e6f-9128749ba679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding a 'document_id' column that is the row number starting from 1\n",
    "eval_text = eval_text.reset_index()\n",
    "eval_text['document_id'] = range(1, len(eval_text) + 1)\n",
    "eval_text.set_index('document_id', inplace=True)\n",
    "\n",
    "# Counting documents written by each supervisor\n",
    "n_documents = eval_text.groupby('supervisor').size()\n",
    "\n",
    "# Counting PSTs evaluated by each supervisor\n",
    "n_psts = eval_text.groupby('supervisor')['uin_deident'].nunique()\n",
    "\n",
    "# Joining counts back to the eval_text on supervisor\n",
    "eval_text = eval_text.join(n_documents.rename('n_documents'), on='supervisor')\n",
    "eval_text = eval_text.join(n_psts.rename('n_psts'), on='supervisor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e54f7-2ae0-4305-b00b-2a90972478ee",
   "metadata": {},
   "source": [
    "## Creating CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ef6e9b-8a98-42ce-a96e-bece0e9702ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Tokenize with SciKitLearn\n",
    "engine = CountVectorizer()\n",
    "model = engine.fit_transform(eval_text.overallcomments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca7fb9f-e1a6-4dda-b806-24a155395476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple POS grouping function\n",
    "def pos_group(tag):\n",
    "    if tag.startswith('N'):\n",
    "        return 'NOUN'\n",
    "    elif tag.startswith('V'):\n",
    "        return 'VERB'\n",
    "    elif tag.startswith('J'):\n",
    "        return 'ADJECTIVE'\n",
    "    elif tag.startswith('R'):\n",
    "        return 'ADVERB'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "# Initialize the list to collect token data\n",
    "long_format_data = []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for document_id, row in eval_text.iterrows():\n",
    "    document = row['overallcomments']\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    for sentence_num, sentence in enumerate(sentences):\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        tagged_tokens = nltk.pos_tag(tokens)  # Get POS tags for the tokens\n",
    "        for token_num, (token, tag) in enumerate(tagged_tokens):\n",
    "            long_format_data.append({\n",
    "                'document_id': document_id,\n",
    "                'sentence_num': sentence_num + 1,\n",
    "                'token_num': token_num + 1,\n",
    "                'token_str': token.lower(),  # Typically, terms are stored in lower case\n",
    "                'term_str': token,           # Original token as it appears\n",
    "                'pos': tag,                  # POS tag\n",
    "                'pos_group': pos_group(tag)  # Grouped POS tag\n",
    "            })\n",
    "\n",
    "# Create DataFrame from long-format data\n",
    "CORPUS = pd.DataFrame(long_format_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41efcc1-a5e3-4f90-ba77-f596e15d16e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>objective</td>\n",
       "      <td>Objective</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sw</td>\n",
       "      <td>SW</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall</td>\n",
       "      <td>recall</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reasons</td>\n",
       "      <td>reasons</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11385</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>36</th>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>opening</td>\n",
       "      <td>opening</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>closure</td>\n",
       "      <td>closure</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    token_str   term_str  pos  pos_group\n",
       "document_id sentence_num token_num                                      \n",
       "1           1            1          objective  Objective   NN       NOUN\n",
       "                         2                  :          :    :      OTHER\n",
       "                         3                 sw         SW  NNP       NOUN\n",
       "                         4             recall     recall  VBP       VERB\n",
       "                         5            reasons    reasons  NNS       NOUN\n",
       "...                                       ...        ...  ...        ...\n",
       "11385       2            36              good       good   JJ  ADJECTIVE\n",
       "                         37           opening    opening   NN       NOUN\n",
       "                         38               and        and   CC      OTHER\n",
       "                         39           closure    closure   NN       NOUN\n",
       "                         40                 .          .    .      OTHER\n",
       "\n",
       "[1444414 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS.set_index(['document_id', 'sentence_num', 'token_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f53f4c1-672e-41f3-a3e1-e80824a0ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS.to_csv(base_path + \"output/CORPUS.csv\", sep='|', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe241786-39a8-49e3-8968-72d2393dc611",
   "metadata": {},
   "source": [
    "## Creating LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c270976a-37cc-4ed4-92c0-39c8ef12dd98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the new DataFrame LIB from eval_text\n",
    "LIB = eval_text[['supervisor', 'uin_deident', 'order_alt', 'n_documents', 'n_psts', 'overallcomments']].copy()\n",
    "\n",
    "# Count the number of sentences per document\n",
    "sentence_counts = CORPUS.groupby('document_id')['sentence_num'].nunique().rename('sentence_count')\n",
    "\n",
    "# Count the number of tokens per document\n",
    "token_counts = CORPUS.groupby('document_id')['token_num'].size().rename('token_count')\n",
    "\n",
    "# Combine sentence and token counts into a single DataFrame\n",
    "doc_counts = pd.DataFrame({'sentence_count': sentence_counts, 'token_count': token_counts})\n",
    "\n",
    "#Merge LIB with document count information\n",
    "LIB = LIB.join(doc_counts)\n",
    "\n",
    "# Get a count of the characters in the comments\n",
    "LIB['char_count'] = eval_text['overallcomments'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1eb0ef-9342-4d0d-b9b8-b32d850fd64e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supervisor</th>\n",
       "      <th>uin_deident</th>\n",
       "      <th>order_alt</th>\n",
       "      <th>n_documents</th>\n",
       "      <th>n_psts</th>\n",
       "      <th>overallcomments</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry, James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>46</td>\n",
       "      <td>Objective:  SW recall reasons why the Industri...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Henry, James</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>46</td>\n",
       "      <td>Objective:  Causes of WW1 (Many districts will...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hoelscher, Nita</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>51</td>\n",
       "      <td>Very well done powerpoint on terrorism in mode...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Opitz, Lynda</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>84</td>\n",
       "      <td>It was good to see you in action with your kid...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opitz, Lynda</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>306</td>\n",
       "      <td>84</td>\n",
       "      <td>I enjoy our work together.  You are seeking wa...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>Clark, Cindy</td>\n",
       "      <td>3251</td>\n",
       "      <td>2</td>\n",
       "      <td>103</td>\n",
       "      <td>28</td>\n",
       "      <td>Maddie wants to be a good teacher.  She is an ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>Clark, Cindy</td>\n",
       "      <td>3251</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>28</td>\n",
       "      <td>Maddie is a confident student.  She cares abou...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>Clark, Cindy</td>\n",
       "      <td>3251</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>28</td>\n",
       "      <td>Madeline has good control of the classroom.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11384</th>\n",
       "      <td>Johnson, Sandy</td>\n",
       "      <td>3252</td>\n",
       "      <td>1</td>\n",
       "      <td>737</td>\n",
       "      <td>194</td>\n",
       "      <td>Miranda - The overall rating on today's lesson...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11385</th>\n",
       "      <td>Solomon, Janet</td>\n",
       "      <td>3253</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Tori appeared confident in the classroom, grea...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11385 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  supervisor  uin_deident  order_alt  n_documents  n_psts  \\\n",
       "document_id                                                                 \n",
       "1               Henry, James            1          1          172      46   \n",
       "2               Henry, James            1          2          172      46   \n",
       "3            Hoelscher, Nita            2          1          185      51   \n",
       "4               Opitz, Lynda            3          1          306      84   \n",
       "5               Opitz, Lynda            3          2          306      84   \n",
       "...                      ...          ...        ...          ...     ...   \n",
       "11381           Clark, Cindy         3251          2          103      28   \n",
       "11382           Clark, Cindy         3251          4          103      28   \n",
       "11383           Clark, Cindy         3251          1          103      28   \n",
       "11384         Johnson, Sandy         3252          1          737     194   \n",
       "11385         Solomon, Janet         3253          1            5       3   \n",
       "\n",
       "                                               overallcomments  \\\n",
       "document_id                                                      \n",
       "1            Objective:  SW recall reasons why the Industri...   \n",
       "2            Objective:  Causes of WW1 (Many districts will...   \n",
       "3            Very well done powerpoint on terrorism in mode...   \n",
       "4            It was good to see you in action with your kid...   \n",
       "5            I enjoy our work together.  You are seeking wa...   \n",
       "...                                                        ...   \n",
       "11381        Maddie wants to be a good teacher.  She is an ...   \n",
       "11382        Maddie is a confident student.  She cares abou...   \n",
       "11383              Madeline has good control of the classroom.   \n",
       "11384        Miranda - The overall rating on today's lesson...   \n",
       "11385        Tori appeared confident in the classroom, grea...   \n",
       "\n",
       "             sentence_count  token_count  char_count  \n",
       "document_id                                           \n",
       "1                      18.0        410.0        2198  \n",
       "2                      19.0        289.0        1499  \n",
       "3                       8.0        175.0         855  \n",
       "4                       5.0        119.0         602  \n",
       "5                       7.0        147.0         772  \n",
       "...                     ...          ...         ...  \n",
       "11381                   2.0         23.0         116  \n",
       "11382                   3.0         32.0         169  \n",
       "11383                   1.0          8.0          43  \n",
       "11384                   8.0        117.0         653  \n",
       "11385                   2.0         85.0         472  \n",
       "\n",
       "[11385 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14caa85f-52e2-404c-a585-c23fb8fff339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688.8596398770312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB['char_count'].fillna(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b97fd0f-a0fa-4eb3-9aee-793e5970c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.to_csv(base_path + \"output/LIB.csv\", sep='|', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969c322-1d01-4890-ab44-35f533f1dff2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Sentence-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcaa40a-213f-46f7-82f2-4254ff3e41e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>term_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_id</th>\n",
       "      <th>sentence_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>Objective : SW recall reasons why the Industri...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Class began with you posing a question to the ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( Car ) You introduced the Industrial Revoluti...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The fact that most students arrive at school e...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You prepared and projected a power point prese...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">11384</th>\n",
       "      <th>6</th>\n",
       "      <td>You have been prompt , extremely reflective , ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good detail on your lesson plans !</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This sets you up for success .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">11385</th>\n",
       "      <th>1</th>\n",
       "      <td>Tori appeared confident in the classroom , gre...</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She referred to prior learning , modeled expec...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   sentence  \\\n",
       "document_id sentence_num                                                      \n",
       "1           1             Objective : SW recall reasons why the Industri...   \n",
       "            2             Class began with you posing a question to the ...   \n",
       "            3             ( Car ) You introduced the Industrial Revoluti...   \n",
       "            4             The fact that most students arrive at school e...   \n",
       "            5             You prepared and projected a power point prese...   \n",
       "...                                                                     ...   \n",
       "11384       6             You have been prompt , extremely reflective , ...   \n",
       "            7                            Good detail on your lesson plans !   \n",
       "            8                                This sets you up for success .   \n",
       "11385       1             Tori appeared confident in the classroom , gre...   \n",
       "            2             She referred to prior learning , modeled expec...   \n",
       "\n",
       "                          term_count  \n",
       "document_id sentence_num              \n",
       "1           1                     17  \n",
       "            2                     19  \n",
       "            3                     26  \n",
       "            4                     29  \n",
       "            5                     23  \n",
       "...                              ...  \n",
       "11384       6                     11  \n",
       "            7                      7  \n",
       "            8                      7  \n",
       "11385       1                     45  \n",
       "            2                     40  \n",
       "\n",
       "[91118 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Aggregate terms to form sentences and count terms\n",
    "grouped = CORPUS.groupby(['document_id', 'sentence_num'])\n",
    "SENTENCES = pd.DataFrame({\n",
    "    'sentence': grouped['term_str'].apply(' '.join),\n",
    "    'term_count': grouped['term_str'].size()\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the column multi-levels generated by agg\n",
    "SENTENCES.columns = ['document_id', 'sentence_num', 'sentence', 'term_count']\n",
    "\n",
    "SENTENCES.set_index(['document_id', 'sentence_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbdbb8db-8860-4ccf-9b68-0d7001a275b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTENCES.to_csv(base_path + \"output/SENTENCES.csv\", sep='|', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c68d4-56ff-4e86-bc46-a77c271ee143",
   "metadata": {},
   "source": [
    "## Creating VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5ca3a0c-a63d-48e8-9225-66e31ec86392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate Term Frequency across the corpus\n",
    "CORPUS['term_str'] = CORPUS['token_str'].str.lower()  # normalize to lowercase\n",
    "TF = CORPUS['term_str'].value_counts().rename('n')\n",
    "\n",
    "# Calculate Document Frequency\n",
    "DF = CORPUS.groupby('term_str')['document_id'].nunique().rename('df')\n",
    "\n",
    "# Calculate IDF using log scaling\n",
    "total_documents = CORPUS['document_id'].nunique()\n",
    "IDF = np.log(total_documents / DF).rename('idf')\n",
    "\n",
    "# Calculate DFIDF\n",
    "DFIDF = (DF * IDF).rename('dfidf')\n",
    "\n",
    "# Stemming and identifying stopwords\n",
    "VOCAB = pd.DataFrame(index=TF.index)\n",
    "VOCAB['n'] = TF\n",
    "VOCAB['df'] = DF\n",
    "VOCAB['idf'] = IDF\n",
    "VOCAB['dfidf'] = DFIDF\n",
    "VOCAB['porter_stem'] = VOCAB.index.map(lambda x: stemmer.stem(x))\n",
    "VOCAB['stop'] = VOCAB.index.isin(stop_words)\n",
    "\n",
    "# Get max POS and POS group for each term\n",
    "max_pos = CORPUS.groupby('term_str')['pos'].agg(lambda x: x.value_counts().idxmax()).rename('max_pos')\n",
    "max_pos_group = CORPUS.groupby('term_str')['pos_group'].agg(lambda x: x.value_counts().idxmax()).rename('max_pos_group')\n",
    "\n",
    "VOCAB = VOCAB.join(max_pos)\n",
    "VOCAB = VOCAB.join(max_pos_group)\n",
    "\n",
    "# Assuming handling of ngrams if applicable\n",
    "# Here we assume unigram as example; modify if you have actual ngrams data\n",
    "VOCAB['ngram_length'] = VOCAB.index.map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad30e919-d908-4b26-8566-d55cbee834a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>dfidf</th>\n",
       "      <th>porter_stem</th>\n",
       "      <th>stop</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>ngram_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>82440</td>\n",
       "      <td>10800</td>\n",
       "      <td>0.040733</td>\n",
       "      <td>439.917498</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>66930</td>\n",
       "      <td>9659</td>\n",
       "      <td>0.152389</td>\n",
       "      <td>1471.926439</td>\n",
       "      <td>the</td>\n",
       "      <td>True</td>\n",
       "      <td>DT</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>45948</td>\n",
       "      <td>10046</td>\n",
       "      <td>0.113105</td>\n",
       "      <td>1136.249721</td>\n",
       "      <td>and</td>\n",
       "      <td>True</td>\n",
       "      <td>CC</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>43763</td>\n",
       "      <td>9629</td>\n",
       "      <td>0.155500</td>\n",
       "      <td>1497.308128</td>\n",
       "      <td>to</td>\n",
       "      <td>True</td>\n",
       "      <td>TO</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>37686</td>\n",
       "      <td>7320</td>\n",
       "      <td>0.429669</td>\n",
       "      <td>3145.176405</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>,</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nesrsta</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>nesrsta</td>\n",
       "      <td>False</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'compare</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>'compar</td>\n",
       "      <td>False</td>\n",
       "      <td>POS</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'contrast</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>'contrast</td>\n",
       "      <td>False</td>\n",
       "      <td>POS</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'vehicle</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>'vehicl</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone/variation</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>9.328035</td>\n",
       "      <td>tone/vari</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21234 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n     df       idf        dfidf porter_stem   stop  \\\n",
       "term_str                                                                 \n",
       ".               82440  10800  0.040733   439.917498           .  False   \n",
       "the             66930   9659  0.152389  1471.926439         the   True   \n",
       "and             45948  10046  0.113105  1136.249721         and   True   \n",
       "to              43763   9629  0.155500  1497.308128          to   True   \n",
       ",               37686   7320  0.429669  3145.176405           ,  False   \n",
       "...               ...    ...       ...          ...         ...    ...   \n",
       "nesrsta             1      1  9.328035     9.328035     nesrsta  False   \n",
       "'compare            1      1  9.328035     9.328035     'compar  False   \n",
       "'contrast           1      1  9.328035     9.328035   'contrast  False   \n",
       "'vehicle            1      1  9.328035     9.328035     'vehicl  False   \n",
       "tone/variation      1      1  9.328035     9.328035   tone/vari  False   \n",
       "\n",
       "               max_pos max_pos_group  ngram_length  \n",
       "term_str                                            \n",
       ".                    .         OTHER             1  \n",
       "the                 DT         OTHER             1  \n",
       "and                 CC         OTHER             1  \n",
       "to                  TO         OTHER             1  \n",
       ",                    ,         OTHER             1  \n",
       "...                ...           ...           ...  \n",
       "nesrsta            NNP          NOUN             1  \n",
       "'compare           POS         OTHER             1  \n",
       "'contrast          POS         OTHER             1  \n",
       "'vehicle            NN          NOUN             1  \n",
       "tone/variation      NN          NOUN             1  \n",
       "\n",
       "[21234 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8dd186c-2297-4eb9-8415-4bce84f62642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB.to_csv(base_path + \"output/VOCAB.csv\", sep='|', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f38c4-52cb-4be7-aa17-941b3c7bde03",
   "metadata": {},
   "source": [
    "### Top 20 most significant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5c20f1-019a-4712-8d17-78d0193c04f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>df</th>\n",
       "      <th>idf</th>\n",
       "      <th>dfidf</th>\n",
       "      <th>porter_stem</th>\n",
       "      <th>stop</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>ngram_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>11241</td>\n",
       "      <td>4108</td>\n",
       "      <td>1.007343</td>\n",
       "      <td>4138.164813</td>\n",
       "      <td>she</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classroom</th>\n",
       "      <td>5945</td>\n",
       "      <td>4053</td>\n",
       "      <td>1.020822</td>\n",
       "      <td>4137.391113</td>\n",
       "      <td>classroom</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teacher</th>\n",
       "      <td>6408</td>\n",
       "      <td>4048</td>\n",
       "      <td>1.022056</td>\n",
       "      <td>4137.283918</td>\n",
       "      <td>teacher</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>8089</td>\n",
       "      <td>3990</td>\n",
       "      <td>1.036488</td>\n",
       "      <td>4135.587140</td>\n",
       "      <td>were</td>\n",
       "      <td>True</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>6439</td>\n",
       "      <td>3917</td>\n",
       "      <td>1.054953</td>\n",
       "      <td>4132.251610</td>\n",
       "      <td>thi</td>\n",
       "      <td>True</td>\n",
       "      <td>DT</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>8423</td>\n",
       "      <td>4375</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>4131.630633</td>\n",
       "      <td>as</td>\n",
       "      <td>True</td>\n",
       "      <td>IN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>8463</td>\n",
       "      <td>4403</td>\n",
       "      <td>0.937993</td>\n",
       "      <td>4129.983659</td>\n",
       "      <td>are</td>\n",
       "      <td>True</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>5814</td>\n",
       "      <td>3836</td>\n",
       "      <td>1.075849</td>\n",
       "      <td>4126.957066</td>\n",
       "      <td>veri</td>\n",
       "      <td>True</td>\n",
       "      <td>RB</td>\n",
       "      <td>ADVERB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>10483</td>\n",
       "      <td>3754</td>\n",
       "      <td>1.097457</td>\n",
       "      <td>4119.854695</td>\n",
       "      <td>her</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>8954</td>\n",
       "      <td>3731</td>\n",
       "      <td>1.103603</td>\n",
       "      <td>4117.542575</td>\n",
       "      <td>your</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>4871</td>\n",
       "      <td>3658</td>\n",
       "      <td>1.123363</td>\n",
       "      <td>4109.260705</td>\n",
       "      <td>well</td>\n",
       "      <td>False</td>\n",
       "      <td>RB</td>\n",
       "      <td>ADVERB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>5940</td>\n",
       "      <td>3589</td>\n",
       "      <td>1.142406</td>\n",
       "      <td>4100.093783</td>\n",
       "      <td>student</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>5672</td>\n",
       "      <td>3579</td>\n",
       "      <td>1.145196</td>\n",
       "      <td>4098.655783</td>\n",
       "      <td>be</td>\n",
       "      <td>True</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>4521</td>\n",
       "      <td>3559</td>\n",
       "      <td>1.150800</td>\n",
       "      <td>4095.695881</td>\n",
       "      <td>job</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>7920</td>\n",
       "      <td>4811</td>\n",
       "      <td>0.849374</td>\n",
       "      <td>4086.339628</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJECTIVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>6032</td>\n",
       "      <td>3481</td>\n",
       "      <td>1.172960</td>\n",
       "      <td>4083.072462</td>\n",
       "      <td>class</td>\n",
       "      <td>False</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>6252</td>\n",
       "      <td>3442</td>\n",
       "      <td>1.184227</td>\n",
       "      <td>4076.107744</td>\n",
       "      <td>i</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>9742</td>\n",
       "      <td>4894</td>\n",
       "      <td>0.832269</td>\n",
       "      <td>4073.125811</td>\n",
       "      <td>that</td>\n",
       "      <td>True</td>\n",
       "      <td>IN</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>21409</td>\n",
       "      <td>4912</td>\n",
       "      <td>0.828598</td>\n",
       "      <td>4070.073597</td>\n",
       "      <td>you</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>5971</td>\n",
       "      <td>3387</td>\n",
       "      <td>1.200335</td>\n",
       "      <td>4065.533500</td>\n",
       "      <td>it</td>\n",
       "      <td>True</td>\n",
       "      <td>PRP</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               n    df       idf        dfidf porter_stem   stop max_pos  \\\n",
       "term_str                                                                   \n",
       "she        11241  4108  1.007343  4138.164813         she   True     PRP   \n",
       "classroom   5945  4053  1.020822  4137.391113   classroom  False      NN   \n",
       "teacher     6408  4048  1.022056  4137.283918     teacher  False      NN   \n",
       "were        8089  3990  1.036488  4135.587140        were   True     VBD   \n",
       "this        6439  3917  1.054953  4132.251610         thi   True      DT   \n",
       "as          8423  4375  0.944373  4131.630633          as   True      IN   \n",
       "are         8463  4403  0.937993  4129.983659         are   True     VBP   \n",
       "very        5814  3836  1.075849  4126.957066        veri   True      RB   \n",
       "her        10483  3754  1.097457  4119.854695         her   True    PRP$   \n",
       "your        8954  3731  1.103603  4117.542575        your   True    PRP$   \n",
       "well        4871  3658  1.123363  4109.260705        well  False      RB   \n",
       "student     5940  3589  1.142406  4100.093783     student  False      NN   \n",
       "be          5672  3579  1.145196  4098.655783          be   True      VB   \n",
       "job         4521  3559  1.150800  4095.695881         job  False      NN   \n",
       "good        7920  4811  0.849374  4086.339628        good  False      JJ   \n",
       "class       6032  3481  1.172960  4083.072462       class  False      NN   \n",
       "i           6252  3442  1.184227  4076.107744           i   True     PRP   \n",
       "that        9742  4894  0.832269  4073.125811        that   True      IN   \n",
       "you        21409  4912  0.828598  4070.073597         you   True     PRP   \n",
       "it          5971  3387  1.200335  4065.533500          it   True     PRP   \n",
       "\n",
       "          max_pos_group  ngram_length  \n",
       "term_str                               \n",
       "she               OTHER             1  \n",
       "classroom          NOUN             1  \n",
       "teacher            NOUN             1  \n",
       "were               VERB             1  \n",
       "this              OTHER             1  \n",
       "as                OTHER             1  \n",
       "are                VERB             1  \n",
       "very             ADVERB             1  \n",
       "her               OTHER             1  \n",
       "your              OTHER             1  \n",
       "well             ADVERB             1  \n",
       "student            NOUN             1  \n",
       "be                 VERB             1  \n",
       "job                NOUN             1  \n",
       "good          ADJECTIVE             1  \n",
       "class              NOUN             1  \n",
       "i                 OTHER             1  \n",
       "that              OTHER             1  \n",
       "you               OTHER             1  \n",
       "it                OTHER             1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting by DFIDF to find the top 20 significant words\n",
    "top_20_significant = VOCAB.sort_values(by='dfidf', ascending=False).head(20)\n",
    "top_20_significant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
